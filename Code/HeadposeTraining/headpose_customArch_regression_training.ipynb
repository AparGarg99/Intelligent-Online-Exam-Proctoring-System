{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9da2a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Input,Dropout,Conv2D,BatchNormalization,Flatten,Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras import regularizers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from collections import Counter\n",
    "from tensorflow.keras.models import load_model\n",
    "from glob import glob\n",
    "import random\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from random import randrange\n",
    "import json\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef433e1",
   "metadata": {},
   "source": [
    "# Get list of train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4052ec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No: Training data : 101656\n",
      "No: Val data : 30809\n"
     ]
    }
   ],
   "source": [
    "oModelPath = \"D:\\\\ISS_project\\\\Model\\\\\"\n",
    "#input path for full image\n",
    "oTrainFullImgPath = \"D:\\\\ISS_project\\\\dataset\\\\prepared_data\\\\train\"\n",
    "oValFullImgPath = \"D:\\\\ISS_project\\\\dataset\\\\prepared_data\\\\val\"\n",
    "\n",
    "def list_image_files(oInputPath):\n",
    "    oImageFileNames = glob(oInputPath + \"\\\\*.png\")\n",
    "    return oImageFileNames\n",
    "\n",
    "oListTrainImgFiles =  list_image_files(oTrainFullImgPath)\n",
    "oListValImgFiles = list_image_files(oValFullImgPath)\n",
    "\n",
    "print(\"No: Training data :\",len(oListTrainImgFiles))\n",
    "print(\"No: Val data :\",len(oListValImgFiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e34f21",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35457e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, list_IDs,image_path,Flag,\n",
    "                 to_fit=True, batch_size=32, dim=(100,100),no_input = 5,\n",
    "                 n_channels=3, n_classes=2, shuffle=True): \n",
    "        self.list_IDs = list_IDs\n",
    "        self.image_path = image_path\n",
    "        self.to_fit = to_fit\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.flag = Flag\n",
    "        self.no_input = no_input\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\n",
    "        :return: number of batches per epoch\n",
    "        \"\"\"\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\n",
    "        :return: X and y when fitting. X only when predicting\n",
    "        \"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        # Generate data\n",
    "        X,y = self._generate_X(list_IDs_temp) \n",
    "\n",
    "        if self.to_fit:\n",
    "            for k in range(0,X.shape[0]):\n",
    "                if self.flag == 'train':\n",
    "                    oAugIdx = randrange(4)\n",
    "                    if oAugIdx == 1:\n",
    "                        X[k,],y[k,] =self._horizontal_flip(X[k],y[k])\n",
    "                    if oAugIdx == 2:\n",
    "                        X[k,],y[k,]=self._random_zoom(X[k],y[k])\n",
    "                    if oAugIdx == 3:\n",
    "                        X[k,]=self._image_translation(X[k])\n",
    "                    \n",
    "            return X,y\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates indexes after each epoch\n",
    "        \"\"\"\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def _generate_X(self, list_IDs_temp):\n",
    "        \"\"\"Generates data containing batch_size images\n",
    "        :param list_IDs_temp: list of label ids to load\n",
    "        :return: batch of images\n",
    "        \"\"\"\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        Y = np.empty((self.batch_size,3))\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = self._load_image(ID)\n",
    "            #getlabel file name\n",
    "            oImageName = ID.split(\"\\\\\")[-1]\n",
    "            oImageName = oImageName.split(\".png\")[0]\n",
    "            oLabelPath = os.path.join(self.image_path,oImageName+\"_angles.txt\")\n",
    "            oLabel = []\n",
    "            with open(oLabelPath, 'r') as f:\n",
    "                oLabel = json.loads(f.read())\n",
    "                #convert to radians\n",
    "                oLabel[0] = oLabel[0] * np.pi/180\n",
    "                oLabel[1] = oLabel[1] * np.pi/180\n",
    "                oLabel[2] = oLabel[2] * np.pi/180\n",
    "            Y[i,] = np.array(oLabel)\n",
    "            #print(\"ID :\",ID)\n",
    "            #print(\"label : \",Y[i])\n",
    "        return X,Y\n",
    "    def _noisy(self,img, noise_type=\"gauss\"):\n",
    "        '''\n",
    "        ### Adding Noise ###\n",
    "        img: image\n",
    "        cj_type: {gauss: gaussian, sp: salt & pepper}\n",
    "        '''\n",
    "        if noise_type == \"gauss\":\n",
    "            image=img.copy() \n",
    "            mean=0\n",
    "            st=0.7\n",
    "            gauss = np.random.normal(mean,st,image.shape)\n",
    "            gauss = gauss.astype('uint8')\n",
    "            image = cv2.add(image,gauss)\n",
    "            return image\n",
    "    \n",
    "        elif noise_type == \"sp\":\n",
    "            image=img.copy() \n",
    "            prob = 0.05\n",
    "            if len(image.shape) == 2:\n",
    "                black = 0\n",
    "                white = 255            \n",
    "            else:\n",
    "                colorspace = image.shape[2]\n",
    "                if colorspace == 3:  # RGB\n",
    "                    black = np.array([0, 0, 0], dtype='uint8')\n",
    "                    white = np.array([255, 255, 255], dtype='uint8')\n",
    "                else:  # RGBA\n",
    "                    black = np.array([0, 0, 0, 255], dtype='uint8')\n",
    "                    white = np.array([255, 255, 255, 255], dtype='uint8')\n",
    "            probs = np.random.random(image.shape[:2])\n",
    "            image[probs < (prob / 2)] = black\n",
    "            image[probs > 1 - (prob / 2)] = white\n",
    "            return image\n",
    "    \n",
    "    def _colorjitter(self,img, cj_type=\"b\"):\n",
    "        '''\n",
    "        ### Different Color Jitter ###\n",
    "        img: image\n",
    "        cj_type: {b: brightness, s: saturation, c: constast}\n",
    "        '''\n",
    "        if cj_type == \"b\":\n",
    "            #value = random.randint(-30, 30)\n",
    "            value = np.random.choice(np.array([-50, -40, -30, 30, 40, 50]))\n",
    "            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "            h, s, v = cv2.split(hsv)\n",
    "            if value >= 0:\n",
    "                lim = 255 - value\n",
    "                v[v > lim] = 255\n",
    "                v[v <= lim] += value\n",
    "            else:\n",
    "                lim = np.absolute(value)\n",
    "                v[v < lim] = 0\n",
    "                v[v >= lim] -= np.absolute(value)\n",
    "\n",
    "            final_hsv = cv2.merge((h, s, v))\n",
    "            img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "            return img\n",
    "    \n",
    "        elif cj_type == \"s\":\n",
    "            # value = random.randint(-50, 50)\n",
    "            value = np.random.choice(np.array([-50, -40, -30, 30, 40, 50]))\n",
    "            hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "            h, s, v = cv2.split(hsv)\n",
    "            if value >= 0:\n",
    "                lim = 255 - value\n",
    "                s[s > lim] = 255\n",
    "                s[s <= lim] += value\n",
    "            else:\n",
    "                lim = np.absolute(value)\n",
    "                s[s < lim] = 0\n",
    "                s[s >= lim] -= np.absolute(value)\n",
    "\n",
    "            final_hsv = cv2.merge((h, s, v))\n",
    "            img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "            return img\n",
    "    \n",
    "        elif cj_type == \"c\":\n",
    "            brightness = 10\n",
    "            contrast = random.randint(40, 100)\n",
    "            dummy = np.int16(img)\n",
    "            dummy = dummy * (contrast/127+1) - contrast + brightness\n",
    "            dummy = np.clip(dummy, 0, 255)\n",
    "            img = np.uint8(dummy)\n",
    "            return img\n",
    "    \n",
    "    def _change_brightness(self,img, value):\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h, s, v = cv2.split(hsv)\n",
    "        v = cv2.add(v,value)\n",
    "        v[v > 255] = 255\n",
    "        v[v < 0] = 0\n",
    "        final_hsv = cv2.merge((h, s, v))\n",
    "        img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "        return img\n",
    "\n",
    "    def _horizontal_flip(self,x,y):\n",
    "        x = cv2.flip(x, 1)\n",
    "        y[1] = -1 * y[1]\n",
    "        y[2] = -1 * y[2]\n",
    "        #x = np.reshape(x,(x.shape[0],x.shape[1],1))\n",
    "        return x,y\n",
    "    def _image_translation(self,image):\n",
    "        width = image.shape[1]\n",
    "        height = image.shape[0]\n",
    "        #tx = np.random.choice(np.array([-45, -40, -35,-30,-25,-20,45,40,35,30,25,20]))\n",
    "        #ty = np.random.choice(np.array([-35,-30,-25,-20,45,40,35,30,25,20]))\n",
    "        oRandIdx = randrange(3)\n",
    "        if oRandIdx == 0:\n",
    "            tx = np.random.choice(np.array([-45, -40, -35,-30,-25,-20,45,40,35,30,25,20]))\n",
    "            ty = 0\n",
    "        if oRandIdx == 1:\n",
    "            ty = randrange(-35,35)\n",
    "            tx = 0\n",
    "        if oRandIdx == 2:   \n",
    "            tx, ty = randrange(-45,45), randrange(-35,35)\n",
    "        # create the translation matrix using tx and ty, it is a NumPy array\n",
    "        translation_matrix = np.array([[1, 0, tx],[0, 1, ty]], dtype=np.float32)\n",
    "        translated_image = cv2.warpAffine(src=image, M=translation_matrix, dsize=(width, height),borderMode = cv2.BORDER_REFLECT)\n",
    "        return translated_image\n",
    "    def _clipped_zoom(self,img, zoom_factor):\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # For multichannel images we don't want to apply the zoom factor to the RGB\n",
    "        # dimension, so instead we create a tuple of zoom factors, one per array\n",
    "        # dimension, with 1's for any trailing dimensions after the width and height.\n",
    "        zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
    "\n",
    "        # Zooming out\n",
    "        if zoom_factor < 1:\n",
    "\n",
    "            # Bounding box of the zoomed-out image within the output array\n",
    "            zh = int(np.round(h * zoom_factor))\n",
    "            zw = int(np.round(w * zoom_factor))\n",
    "            top = (h - zh) // 2\n",
    "            left = (w - zw) // 2\n",
    "\n",
    "            # Zero-padding\n",
    "            out = np.zeros_like(img)\n",
    "            out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple)\n",
    "\n",
    "        # Zooming in\n",
    "        elif zoom_factor > 1:\n",
    "\n",
    "            # Bounding box of the zoomed-in region within the input array\n",
    "            zh = int(np.round(h / zoom_factor))\n",
    "            zw = int(np.round(w / zoom_factor))\n",
    "            top = (h - zh) // 2\n",
    "            left = (w - zw) // 2\n",
    "\n",
    "            out = zoom(img[top:top+zh, left:left+zw], zoom_tuple)\n",
    "\n",
    "            # `out` might still be slightly larger than `img` due to rounding, so\n",
    "            # trim off any extra pixels at the edges\n",
    "            trim_top = ((out.shape[0] - h) // 2)\n",
    "            trim_left = ((out.shape[1] - w) // 2)\n",
    "            out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
    "\n",
    "        # If zoom_factor == 1, just return the input array\n",
    "        else:\n",
    "            out = img\n",
    "        return out\n",
    "    def _random_zoom(self,x,y):\n",
    "        ranges =  randrange(10)\n",
    "        while ranges == 4 or ranges == 6 or ranges == 0 or ranges == 9 or ranges == 8:\n",
    "            ranges =  randrange(10)\n",
    "        zoom_factor = 1 + ranges/10\n",
    "        x = self._clipped_zoom(x, zoom_factor)\n",
    "        return x,y\n",
    "    \n",
    "    def _load_image(self, image_path):\n",
    "        #print(\"image_path :\",image_path)\n",
    "        img = cv2.imread(image_path)\n",
    "        '''Change brightness'''\n",
    "        if self.flag == 'train':\n",
    "            oIdx = randrange(2)\n",
    "            if oIdx == 1:\n",
    "                oIdxType = randrange(3)\n",
    "                cj_type = [\"b\",\"s\",\"c\"]\n",
    "                #value = randrange(-30,30)\n",
    "                img = self._colorjitter(img, cj_type=cj_type[oIdxType])\n",
    "                \n",
    "        '''Adding Noise'''\n",
    "        if self.flag == 'train':\n",
    "            oIdx = randrange(2)\n",
    "            if oIdx == 1:\n",
    "                oIdxType = randrange(2)\n",
    "                noise_type = [\"gauss\",\"sp\"]\n",
    "                #value = randrange(-30,30)\n",
    "                img = self._noisy(img, noise_type=noise_type[oIdxType])\n",
    "                \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #img = cv2.equalizeHist(img)\n",
    "        #mean = [0.485, 0.456, 0.406]\n",
    "        #std = [0.229, 0.224, 0.225]\n",
    "        img = img/255.0\n",
    "        #img = (img - mean) / std\n",
    "        #img = np.reshape(img,(img.shape[0],img.shape[1],1))\n",
    "        #print(\"shape: \",img.shape)\n",
    "        return img\n",
    "    \n",
    "flagTrain = 'train'    \n",
    "oTrainGen = DataGenerator(oListTrainImgFiles,oTrainFullImgPath,flagTrain)\n",
    "flagVal = 'val'\n",
    "oValGen = DataGenerator(oListValImgFiles,oValFullImgPath,flagVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a2b16d",
   "metadata": {},
   "source": [
    "# Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bad97959",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 24)        1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 48, 48, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 48, 48, 24)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 48, 48, 24)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 23, 23, 48)        10416     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 23, 23, 48)        192       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 23, 23, 48)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 23, 23, 48)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 11, 11, 64)        27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "block3.5_conv3.5 (Conv2D)    (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 4, 4, 96)          55392     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 4, 4, 96)          384       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv5 (Conv2D)        (None, 1, 1, 128)         110720    \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten1 (Flatten)           (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_fc1 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "fc_2 (Dense)                 (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 261,075\n",
      "Trainable params: 260,483\n",
      "Non-trainable params: 592\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(100,100,3))\n",
    "#x = tf.cast(input_tensor, tf.float32)\n",
    "#x = tf.keras.applications.mobilenet.preprocess_input(x)    \n",
    "#base_model = MobileNetV2(input_tensor=x,weights = 'imagenet',input_shape = (100,100,3), include_top=False)\n",
    "#base_model.trainable = False    \n",
    "# add a global spatial average pooling layer\n",
    "#x = base_model.output\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "#add a fully-connected layer and the output layer\n",
    "#x = Dropout(0.5)(x)\n",
    "#x = BatchNormalization()(x)\n",
    "#x = Dense(128, activation='tanh')(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "\n",
    "'''custom architecture'''\n",
    "#x = BatchNormalization()(input_tensor)\n",
    "x = Conv2D(24, (5, 5), strides=(2,2), padding='valid', name='block1_conv1')(input_tensor)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dropout(0.2)(x)\n",
    "#x = MaxPooling2D((2, 2), strides=None, name='block1_pool')(x)\n",
    "\n",
    "x = Conv2D(48, (3,3), strides=(2,2),padding='valid', name='block2_conv2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dropout(0.2)(x)\n",
    "#x = MaxPooling2D((2, 2), strides=None, name='block2_pool')(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3),strides=(2,2), padding='valid', name='block3_conv3')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv2D(64, (3, 3),strides=(1,1), padding='valid', name='block3.5_conv3.5')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Conv2D(96, (3, 3),strides=(2,2), padding='valid', name='block4_conv4')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dropout(0.3)(x)\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "#x = MaxPooling2D((2, 2), strides=None, name='block3_pool')(x)\n",
    "#x = Dropout(0.7, name='dropout_conv3')(x)\n",
    "x = Conv2D(128, (3, 3),strides=(2,2), padding='valid', name='block5_conv5')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Activation('tanh')(x)\n",
    "\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Flatten(name='flatten1')(x)\n",
    "#x = Dense(120, name='fc_1')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "#x = Activation('tanh')(x)\n",
    "x = Dropout(0.3, name='dropout_fc1')(x)\n",
    "x = Dense(128, name='fc_2')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Activation('tanh')(x)\n",
    "\n",
    "prediction = Dense(3, activation='linear')(x)\n",
    "\n",
    "# create the model\n",
    "model = Model(inputs=input_tensor, outputs=prediction)\n",
    "model.summary()\n",
    "adam = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1e-5)\n",
    "model.compile(optimizer=adam, loss=\"mean_squared_error\",metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e781668",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a75c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "oFlag = \"Headpose_Regression_model\"\n",
    "checkpoint_path = os.path.join(oModelPath,oFlag + \".hdf5\")\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 monitor ='val_loss',  \n",
    "                                                 save_weights_only=False,\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "#create callbacks for monitoring training\n",
    "tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n",
    "\n",
    "csv_logger      = CSVLogger(os.path.join(oModelPath,oFlag+'.csv'))\n",
    "early_stoping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n",
    "#create callback for reducing learning rate\n",
    "reduce_lr =tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=5, mode = 'min',min_lr=0.000005,verbose =1)\n",
    "\n",
    "callbacks=[cp_callback,tb_callback,csv_logger,early_stoping]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea8ea8",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbff2fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3176/3176 [==============================] - 488s 153ms/step - loss: 0.1003 - mae: 0.2177 - val_loss: 0.0625 - val_mae: 0.1686\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06251, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 2/100\n",
      "3176/3176 [==============================] - 480s 151ms/step - loss: 0.0647 - mae: 0.1727 - val_loss: 0.0521 - val_mae: 0.1490\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06251 to 0.05208, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 3/100\n",
      "3176/3176 [==============================] - 483s 152ms/step - loss: 0.0542 - mae: 0.1570 - val_loss: 0.0460 - val_mae: 0.1501\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05208 to 0.04597, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 4/100\n",
      "3176/3176 [==============================] - 490s 154ms/step - loss: 0.0488 - mae: 0.1487 - val_loss: 0.0474 - val_mae: 0.1486\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.04597\n",
      "Epoch 5/100\n",
      "3176/3176 [==============================] - 481s 151ms/step - loss: 0.0457 - mae: 0.1438 - val_loss: 0.0417 - val_mae: 0.1418\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04597 to 0.04169, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 6/100\n",
      "3176/3176 [==============================] - 480s 151ms/step - loss: 0.0437 - mae: 0.1406 - val_loss: 0.0409 - val_mae: 0.1405\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.04169 to 0.04094, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 7/100\n",
      "3176/3176 [==============================] - 499s 157ms/step - loss: 0.0418 - mae: 0.1379 - val_loss: 0.0428 - val_mae: 0.1453\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04094\n",
      "Epoch 8/100\n",
      "3176/3176 [==============================] - 492s 155ms/step - loss: 0.0407 - mae: 0.1360 - val_loss: 0.0455 - val_mae: 0.1446\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.04094\n",
      "Epoch 9/100\n",
      "3176/3176 [==============================] - 495s 156ms/step - loss: 0.0397 - mae: 0.1345 - val_loss: 0.0398 - val_mae: 0.1344\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04094 to 0.03978, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 10/100\n",
      "3176/3176 [==============================] - 491s 155ms/step - loss: 0.0386 - mae: 0.1328 - val_loss: 0.0415 - val_mae: 0.1384\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03978\n",
      "Epoch 11/100\n",
      "3176/3176 [==============================] - 491s 155ms/step - loss: 0.0379 - mae: 0.1315 - val_loss: 0.0393 - val_mae: 0.1360\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03978 to 0.03932, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 12/100\n",
      "3176/3176 [==============================] - 499s 157ms/step - loss: 0.0368 - mae: 0.1298 - val_loss: 0.0378 - val_mae: 0.1324\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03932 to 0.03776, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 13/100\n",
      "3176/3176 [==============================] - 506s 159ms/step - loss: 0.0367 - mae: 0.1294 - val_loss: 0.0350 - val_mae: 0.1239\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03776 to 0.03498, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 14/100\n",
      "3176/3176 [==============================] - 495s 156ms/step - loss: 0.0362 - mae: 0.1284 - val_loss: 0.0350 - val_mae: 0.1232\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03498 to 0.03496, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 15/100\n",
      "3176/3176 [==============================] - 493s 155ms/step - loss: 0.0356 - mae: 0.1275 - val_loss: 0.0399 - val_mae: 0.1371\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.03496\n",
      "Epoch 16/100\n",
      "3176/3176 [==============================] - 492s 155ms/step - loss: 0.0352 - mae: 0.1269 - val_loss: 0.0382 - val_mae: 0.1305\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.03496\n",
      "Epoch 17/100\n",
      "3176/3176 [==============================] - 496s 156ms/step - loss: 0.0350 - mae: 0.1264 - val_loss: 0.0349 - val_mae: 0.1231\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.03496 to 0.03486, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 18/100\n",
      "3176/3176 [==============================] - 484s 153ms/step - loss: 0.0344 - mae: 0.1255 - val_loss: 0.0375 - val_mae: 0.1335\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.03486\n",
      "Epoch 19/100\n",
      "3176/3176 [==============================] - 483s 152ms/step - loss: 0.0342 - mae: 0.1250 - val_loss: 0.0371 - val_mae: 0.1295\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.03486\n",
      "Epoch 20/100\n",
      "3176/3176 [==============================] - 505s 159ms/step - loss: 0.0337 - mae: 0.1242 - val_loss: 0.0365 - val_mae: 0.1298\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.03486\n",
      "Epoch 21/100\n",
      "3176/3176 [==============================] - 497s 157ms/step - loss: 0.0336 - mae: 0.1239 - val_loss: 0.0373 - val_mae: 0.1302\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.03486\n",
      "Epoch 22/100\n",
      "3176/3176 [==============================] - 487s 153ms/step - loss: 0.0334 - mae: 0.1234 - val_loss: 0.0393 - val_mae: 0.1327\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.03486\n",
      "Epoch 23/100\n",
      "3176/3176 [==============================] - 478s 151ms/step - loss: 0.0333 - mae: 0.1228 - val_loss: 0.0349 - val_mae: 0.1233\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.03486\n",
      "Epoch 24/100\n",
      "3176/3176 [==============================] - 482s 152ms/step - loss: 0.0328 - mae: 0.1224 - val_loss: 0.0342 - val_mae: 0.1235\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.03486 to 0.03420, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 25/100\n",
      "3176/3176 [==============================] - 489s 154ms/step - loss: 0.0327 - mae: 0.1222 - val_loss: 0.0335 - val_mae: 0.1202\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.03420 to 0.03355, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 26/100\n",
      "3176/3176 [==============================] - 490s 154ms/step - loss: 0.0326 - mae: 0.1217 - val_loss: 0.0341 - val_mae: 0.1218\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.03355\n",
      "Epoch 27/100\n",
      "3176/3176 [==============================] - 498s 157ms/step - loss: 0.0321 - mae: 0.1211 - val_loss: 0.0362 - val_mae: 0.1277\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.03355\n",
      "Epoch 28/100\n",
      "3176/3176 [==============================] - 508s 160ms/step - loss: 0.0318 - mae: 0.1207 - val_loss: 0.0389 - val_mae: 0.1380\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.03355\n",
      "Epoch 29/100\n",
      "3176/3176 [==============================] - 513s 162ms/step - loss: 0.0318 - mae: 0.1205 - val_loss: 0.0367 - val_mae: 0.1294\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.03355\n",
      "Epoch 30/100\n",
      "3176/3176 [==============================] - 856s 269ms/step - loss: 0.0318 - mae: 0.1202 - val_loss: 0.0367 - val_mae: 0.1320\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.03355\n",
      "Epoch 31/100\n",
      "3176/3176 [==============================] - 919s 289ms/step - loss: 0.0313 - mae: 0.1194 - val_loss: 0.0340 - val_mae: 0.1221\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.03355\n",
      "Epoch 32/100\n",
      "3176/3176 [==============================] - 591s 186ms/step - loss: 0.0310 - mae: 0.1193 - val_loss: 0.0379 - val_mae: 0.1330\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.03355\n",
      "Epoch 33/100\n",
      "3176/3176 [==============================] - 516s 162ms/step - loss: 0.0312 - mae: 0.1193 - val_loss: 0.0351 - val_mae: 0.1286\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.03355\n",
      "Epoch 34/100\n",
      "3176/3176 [==============================] - 510s 161ms/step - loss: 0.0308 - mae: 0.1184 - val_loss: 0.0324 - val_mae: 0.1201\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.03355 to 0.03238, saving model to D:\\ISS_project\\Model\\Headpose_Regression_model.hdf5\n",
      "Epoch 35/100\n",
      "3176/3176 [==============================] - 506s 159ms/step - loss: 0.0308 - mae: 0.1185 - val_loss: 0.0349 - val_mae: 0.1255\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.03238\n",
      "Epoch 36/100\n",
      "3176/3176 [==============================] - 2206s 695ms/step - loss: 0.0306 - mae: 0.1181 - val_loss: 0.0347 - val_mae: 0.1250\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.03238\n",
      "Epoch 37/100\n",
      "3176/3176 [==============================] - 843s 265ms/step - loss: 0.0305 - mae: 0.1179 - val_loss: 0.0351 - val_mae: 0.1269\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.03238\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3176/3176 [==============================] - 499s 157ms/step - loss: 0.0307 - mae: 0.1180 - val_loss: 0.0369 - val_mae: 0.1309\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.03238\n",
      "Epoch 39/100\n",
      "3176/3176 [==============================] - 508s 160ms/step - loss: 0.0302 - mae: 0.1174 - val_loss: 0.0343 - val_mae: 0.1249\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.03238\n",
      "Epoch 40/100\n",
      " 418/3176 [==>...........................] - ETA: 6:47 - loss: 0.0309 - mae: 0.1180"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9aac3c5e1262>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m results = model.fit(oTrainGen, batch_size=64, epochs=100, callbacks=callbacks,\\\n\u001b[0m\u001b[0;32m      2\u001b[0m                     validation_data=oValGen,shuffle=True,verbose=1)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = model.fit(oTrainGen, batch_size=64, epochs=100, callbacks=callbacks,\\\n",
    "                    validation_data=oValGen,shuffle=True,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba48675c",
   "metadata": {},
   "source": [
    "# Plot Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dbe1738",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dba12caf3319>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# plot loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Learning curve\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# plot loss\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.savefig(\"./hp_regression_loss\")\n",
    "plt.legend();\n",
    "#plot accuracy\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Accuracy curve\")\n",
    "plt.plot(results.history[\"mae\"], label=\"train_mae\")\n",
    "plt.plot(results.history[\"val_mae\"], label=\"val_mae\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"mae\")\n",
    "plt.savefig(\"./hp_regression_mae\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6441d42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oFlag = \"Headpose_Regression_model\"\n",
    "plt.style.use('seaborn')                   # if want to use the default style, set 'classic'\n",
    "plt.rcParams['ytick.right']     = True\n",
    "plt.rcParams['ytick.labelright']= False\n",
    "plt.rcParams['ytick.left']      = True\n",
    "plt.rcParams['ytick.labelleft'] = True\n",
    "plt.rcParams['figure.figsize']  = [7,7]   # Set the figure size to be 7 inch for (width,height)\n",
    "\n",
    "records     = pd.read_csv(os.path.join(oModelPath,oFlag +'.csv'))\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "plt.plot(records['val_loss'], label=\"validation\")\n",
    "plt.plot(records['loss'],label=\"training\")\n",
    "plt.yticks([0.00,0.01,0.02,0.03,0.04,0.05])\n",
    "plt.title('mse curve',fontsize=12)\n",
    "\n",
    "ax= plt.gca()\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(records['val_mae'],label=\"validation\")\n",
    "plt.plot(records['mae'],label=\"training\")\n",
    "plt.yticks([0.08,0.09,0.10,0.11,0.12])\n",
    "plt.title('mae curve',fontsize=12)\n",
    "ax.legend()\n",
    "#save the plot\n",
    "plotpath  = os.path.join(oModelPath,oFlag + '_plot.png')\n",
    "plt.savefig(plotpath)\n",
    "#Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b17b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
